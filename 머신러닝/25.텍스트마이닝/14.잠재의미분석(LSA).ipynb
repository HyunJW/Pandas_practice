{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잠재의미분석(LSA)\n",
    "- 특이값 분해(Singular Value Decomposition, SVD) 차원축소 방법 중 하나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20가지 주제의 뉴스 데이터\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, \n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well i'm not sure about the story nad it did seem biased. What\\nI disagree with is your statement that the U.S. Media is out to\\nruin Israels reputation. That is rediculous. The U.S. media is\\nthe most pro-israeli media in the world. Having lived in Europe\\nI realize that incidences such as the one described in the\\nletter have occured. The U.S. media as a whole seem to try to\\nignore them. The U.S. is subsidizing Israels existance and the\\nEuropeans are not (at least not to the same degree). So I think\\nthat might be a reason they report more clearly on the\\natrocities.\\n\\tWhat is a shame is that in Austria, daily reports of\\nthe inhuman acts commited by Israeli soldiers and the blessing\\nreceived from the Government makes some of the Holocaust guilt\\ngo away. After all, look how the Jews are treating other races\\nwhen they got power. It is unfortunate.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#첫번째 뉴스\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#뉴스 카테고리\n",
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\AppData\\Local\\Temp\\ipykernel_14000\\1949574039.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  news_df['clean_doc'] = news_df['document'].str.replace('[^a-zA-Z]', ' ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'well sure about story seem biased what disagree with your statement that media ruin israels reputation that rediculous media most israeli media world having lived europe realize that incidences such described letter have occured media whole seem ignore them subsidizing israels existance europeans least same degree think that might reason they report more clearly atrocities what shame that austria daily reports inhuman acts commited israeli soldiers blessing received from government makes some holocaust guilt away after look jews treating other races when they power unfortunate'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전처리\n",
    "news_df = pd.DataFrame({'document': documents})\n",
    "# 알파벳 이외의 문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace('[^a-zA-Z]', ' ')\n",
    "\n",
    "# 길이가 3이하인 단어 제거\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(\n",
    "    lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "\n",
    "# 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].str.lower()\n",
    "\n",
    "news_df['clean_doc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well',\n",
       " 'sure',\n",
       " 'story',\n",
       " 'seem',\n",
       " 'biased',\n",
       " 'disagree',\n",
       " 'statement',\n",
       " 'media',\n",
       " 'ruin',\n",
       " 'israels',\n",
       " 'reputation',\n",
       " 'rediculous',\n",
       " 'media',\n",
       " 'israeli',\n",
       " 'media',\n",
       " 'world',\n",
       " 'lived',\n",
       " 'europe',\n",
       " 'realize',\n",
       " 'incidences',\n",
       " 'described',\n",
       " 'letter',\n",
       " 'occured',\n",
       " 'media',\n",
       " 'whole',\n",
       " 'seem',\n",
       " 'ignore',\n",
       " 'subsidizing',\n",
       " 'israels',\n",
       " 'existance',\n",
       " 'europeans',\n",
       " 'least',\n",
       " 'degree',\n",
       " 'think',\n",
       " 'might',\n",
       " 'reason',\n",
       " 'report',\n",
       " 'clearly',\n",
       " 'atrocities',\n",
       " 'shame',\n",
       " 'austria',\n",
       " 'daily',\n",
       " 'reports',\n",
       " 'inhuman',\n",
       " 'acts',\n",
       " 'commited',\n",
       " 'israeli',\n",
       " 'soldiers',\n",
       " 'blessing',\n",
       " 'received',\n",
       " 'government',\n",
       " 'makes',\n",
       " 'holocaust',\n",
       " 'guilt',\n",
       " 'away',\n",
       " 'look',\n",
       " 'jews',\n",
       " 'treating',\n",
       " 'races',\n",
       " 'power',\n",
       " 'unfortunate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#불용어 처리\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# 토큰화\n",
    "tokenized_doc = news_df['clean_doc'].str.split()\n",
    "\n",
    "# 불용어 제거\n",
    "tokenized_doc = tokenized_doc.apply(\n",
    "    lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "tokenized_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well sure story seem biased disagree statement media ruin israels reputation rediculous media israeli media world lived europe realize incidences described letter occured media whole seem ignore subsidizing israels existance europeans least degree think might reason report clearly atrocities shame austria daily reports inhuman acts commited israeli soldiers blessing received government makes holocaust guilt away look jews treating races power unfortunate'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#역토큰화\n",
    "detokenized_doc = []\n",
    "for i in range(len(news_df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "news_df['clean_doc'] = detokenized_doc\n",
    "news_df['clean_doc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF행렬\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 상위 1000개의 단어만 처리\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "#TF-IDF행렬의 크기\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#특이값 분해(SVD)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd_model = TruncatedSVD(n_components=20) # 11314개의 행 => 20개 축소\n",
    "svd_model.fit(X)\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#토픽수 x 단어수\n",
    "import numpy as np\n",
    "np.shape(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01469448,  0.05019038,  0.02132608, ...,  0.0786596 ,\n",
       "         0.01432354,  0.01788787],\n",
       "       [-0.00534551,  0.0165534 , -0.01643801, ..., -0.06356598,\n",
       "        -0.01063255, -0.01906471],\n",
       "       [ 0.0018262 , -0.00369262, -0.01801967, ...,  0.05878623,\n",
       "         0.0262691 ,  0.022265  ],\n",
       "       ...,\n",
       "       [-0.00573767, -0.00045085,  0.0083785 , ...,  0.00471099,\n",
       "         0.0094785 , -0.00282111],\n",
       "       [ 0.00500334, -0.00901498, -0.004393  , ...,  0.0793181 ,\n",
       "         0.00287461,  0.00493287],\n",
       "       [-0.00132898, -0.01115991, -0.00464496, ..., -0.00388068,\n",
       "         0.01768014,  0.00057727]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('like', 0.21386), ('know', 0.20046), ('people', 0.19293), ('think', 0.17805), ('good', 0.15128)]\n",
      "Topic 2: [('thanks', 0.3288), ('windows', 0.29081), ('card', 0.1808), ('drive', 0.17451), ('mail', 0.15121)]\n",
      "Topic 3: [('game', 0.36919), ('team', 0.32548), ('year', 0.28179), ('games', 0.25408), ('season', 0.18453)]\n",
      "Topic 4: [('drive', 0.53192), ('scsi', 0.20426), ('hard', 0.15591), ('disk', 0.15513), ('drives', 0.13795)]\n",
      "Topic 5: [('windows', 0.39942), ('file', 0.24993), ('window', 0.18905), ('files', 0.16168), ('program', 0.13752)]\n",
      "Topic 6: [('mail', 0.16164), ('chip', 0.16034), ('government', 0.15572), ('space', 0.15023), ('information', 0.13649)]\n",
      "Topic 7: [('like', 0.66747), ('bike', 0.13601), ('chip', 0.11478), ('know', 0.10956), ('sounds', 0.10196)]\n",
      "Topic 8: [('card', 0.45326), ('video', 0.21996), ('sale', 0.21344), ('monitor', 0.15775), ('offer', 0.14634)]\n",
      "Topic 9: [('know', 0.45241), ('card', 0.33527), ('chip', 0.1884), ('government', 0.14678), ('video', 0.14436)]\n",
      "Topic 10: [('people', 0.42989), ('like', 0.40489), ('game', 0.15049), ('windows', 0.14442), ('government', 0.12514)]\n",
      "Topic 11: [('think', 0.77707), ('need', 0.10549), ('chip', 0.09672), ('thanks', 0.09663), ('encryption', 0.07775)]\n",
      "Topic 12: [('thanks', 0.36587), ('good', 0.22916), ('right', 0.22208), ('bike', 0.19898), ('problem', 0.19341)]\n",
      "Topic 13: [('good', 0.34746), ('people', 0.32084), ('windows', 0.29509), ('know', 0.24259), ('file', 0.16529)]\n",
      "Topic 14: [('space', 0.41704), ('think', 0.21439), ('know', 0.18469), ('problem', 0.15452), ('nasa', 0.15382)]\n",
      "Topic 15: [('right', 0.38948), ('sale', 0.2185), ('think', 0.2002), ('file', 0.19299), ('window', 0.18384)]\n",
      "Topic 16: [('israel', 0.41496), ('israeli', 0.2204), ('good', 0.19497), ('jews', 0.18797), ('need', 0.17256)]\n",
      "Topic 17: [('time', 0.64443), ('file', 0.2524), ('bike', 0.20407), ('files', 0.13334), ('game', 0.13098)]\n",
      "Topic 18: [('time', 0.2827), ('problem', 0.28027), ('good', 0.2203), ('mail', 0.14613), ('need', 0.13531)]\n",
      "Topic 19: [('year', 0.31824), ('window', 0.26859), ('time', 0.26502), ('windows', 0.16286), ('know', 0.12333)]\n",
      "Topic 20: [('mail', 0.33539), ('windows', 0.29132), ('problem', 0.26885), ('address', 0.2181), ('list', 0.1618)]\n"
     ]
    }
   ],
   "source": [
    "#20개의 뉴스그룹별로 추출한 토픽 리스트 출력\n",
    "terms = vectorizer.get_feature_names_out() # 단어 집합(1000개의 단어)\n",
    "\n",
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print('Topic %d:' % (idx + 1),\n",
    "              [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "\n",
    "get_topics(svd_model.components_, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
