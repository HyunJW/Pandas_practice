{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 감성분석\n",
    "- 텍스트에 나타난 주관적 요소를 분석하여 긍정,부정의 요소 및 그 정도를 판별하여 정량화하는 기법"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 단어사전기반 분석\n",
    "- 감성사전을 이용하여 각 단어의 감정 분류와 그 정도를 알 수 있어야 함\n",
    "- 텍스트와 감성지수가 사전에 정의되어 있어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "pos_review = (glob.glob('c:/data/imdb/train/pos/*.txt'))[20]\n",
    "f = open(pos_review, 'r')\n",
    "lines1 = f.readlines()[0]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#감성분석\n",
    "from afinn import Afinn\n",
    "afinn = Afinn()\n",
    "afinn.score(lines1) # 감성점수 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/data/imdb/train/pos\\\\0_9.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10000_8.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10001_10.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10002_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10003_8.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10004_8.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10005_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10006_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10007_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10008_7.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list(glob.glob('c:/data/imdb/train/pos/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "2.0\n",
      "19.0\n",
      "3.0\n",
      "14.0\n",
      "8.0\n",
      "22.0\n",
      "28.0\n",
      "13.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 긍정리뷰 10개 파일로 테스트\n",
    "afinn = Afinn()\n",
    "for i in files:\n",
    "    f = open(i)\n",
    "    lines1 = f.readlines()[0]\n",
    "    print(afinn.score(lines1))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#부정리뷰 데이터 20번째 내용의 감성점수\n",
    "neg_review = (glob.glob('c:/data/imdb/train/neg/*.txt'))[20]\n",
    "f = open(neg_review, 'r')\n",
    "lines2 = f.readlines()[0]\n",
    "f.close()\n",
    "afinn.score(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/data/imdb/train/neg\\\\0_3.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10000_4.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10001_4.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10002_1.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10003_1.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10004_3.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10005_3.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10006_4.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10007_1.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10008_2.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list(glob.glob('c:/data/imdb/train/neg/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "-4.0\n",
      "9.0\n",
      "5.0\n",
      "-7.0\n",
      "1.0\n",
      "13.0\n",
      "4.0\n",
      "7.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 부정리뷰 10개 파일로 테스트\n",
    "afinn = Afinn()\n",
    "for i in files:\n",
    "    f = open(i)\n",
    "    lines2 = f.readlines()[0]\n",
    "    print(afinn.score(lines2))\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기계학습으로 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#긍정 텍스트 로드\n",
    "pos_review = (glob.glob('c:/data/imdb/train/pos/*.txt'))[:100]\n",
    "lines_pos = []\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except:\n",
    "        continue\n",
    "len(lines_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#부정 텍스트 로드\n",
    "neg_review = (glob.glob('c:/data/imdb/train/neg/*.txt'))[:100]\n",
    "lines_neg = []\n",
    "for i in neg_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_neg.append(temp)\n",
    "        f.close()\n",
    "    except:\n",
    "        continue\n",
    "len(lines_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#긍정, 부정 리뷰 결합\n",
    "total_text = lines_pos + lines_neg\n",
    "len(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "# 긍정, 부정 클래스 라벨링\n",
    "x = np.array(['pos', 'neg'])\n",
    "class_Index = np.repeat(x, [len(lines_pos), len(lines_neg)], axis=0)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF행렬\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words=stop_words).fit(total_text)\n",
    "X_train_vectorized = vect.transform(total_text)\n",
    "X_train_vectorized.index = class_Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 0.10070285188783222\n",
      "189 0.10070285188783222\n",
      "212 0.09513664322740871\n",
      "585 0.06603504311540802\n",
      "773 0.43419192948676516\n",
      "816 0.10070285188783222\n",
      "893 0.09081915636680153\n",
      "1038 0.07740781722251895\n",
      "1066 0.09513664322740871\n",
      "1105 0.0708975934136058\n",
      "1921 0.09081915636680153\n",
      "2034 0.0708975934136058\n",
      "2128 0.06498892497285297\n",
      "2174 0.10854798237169129\n",
      "2210 0.10070285188783222\n",
      "2727 0.3478134336932994\n",
      "2903 0.10070285188783222\n",
      "3008 0.10854798237169129\n",
      "3013 0.10854798237169129\n",
      "3249 0.07944638225969057\n",
      "3320 0.09081915636680153\n",
      "3387 0.049185844603996734\n",
      "3407 0.06831396493884356\n",
      "3563 0.04746484661907397\n",
      "3828 0.040035828354977356\n",
      "4031 0.031912297780574375\n",
      "4179 0.09081915636680153\n",
      "4242 0.10854798237169129\n",
      "4288 0.10070285188783222\n",
      "4358 0.10854798237169129\n",
      "4480 0.10070285188783222\n",
      "4487 0.10854798237169129\n",
      "4618 0.10070285188783222\n",
      "4664 0.09513664322740871\n",
      "4676 0.10854798237169129\n",
      "4757 0.09081915636680153\n",
      "4772 0.10070285188783222\n",
      "4872 0.06305246292974673\n",
      "4956 0.10854798237169129\n",
      "4992 0.10854798237169129\n",
      "5001 0.06498892497285297\n",
      "5020 0.1548156344450379\n",
      "5022 0.10854798237169129\n",
      "5037 0.10854798237169129\n",
      "5078 0.040035828354977356\n",
      "5273 0.07740781722251895\n",
      "5569 0.19027328645481742\n",
      "5570 0.21709596474338258\n",
      "5681 0.09081915636680153\n",
      "5758 0.43419192948676516\n",
      "5760 0.10854798237169129\n",
      "5847 0.04705749531070193\n",
      "5897 0.04031829282374757\n",
      "6032 0.08172530408312614\n",
      "6355 0.09513664322740871\n",
      "6380 0.06399647807823637\n",
      "6498 0.05490262579456099\n"
     ]
    }
   ],
   "source": [
    "for idx,value in enumerate(X_train_vectorized[0].toarray()[0]):\n",
    "    if value>0:\n",
    "        print(idx, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bromwell</th>\n",
       "      <th>high</th>\n",
       "      <th>cartoon</th>\n",
       "      <th>comedy</th>\n",
       "      <th>ran</th>\n",
       "      <th>time</th>\n",
       "      <th>programs</th>\n",
       "      <th>school</th>\n",
       "      <th>life</th>\n",
       "      <th>teachers</th>\n",
       "      <th>...</th>\n",
       "      <th>zombified</th>\n",
       "      <th>auteur</th>\n",
       "      <th>ample</th>\n",
       "      <th>opportunities</th>\n",
       "      <th>golden</th>\n",
       "      <th>geist</th>\n",
       "      <th>uttered</th>\n",
       "      <th>downloading</th>\n",
       "      <th>midget</th>\n",
       "      <th>tricking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6530 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bromwell  high  cartoon  comedy  ran  time  programs  school  life  \\\n",
       "0       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "1       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "2       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "3       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "4       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "\n",
       "   teachers  ...  zombified  auteur  ample  opportunities  golden  geist  \\\n",
       "0       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "1       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "2       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "3       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "4       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "\n",
       "   uttered  downloading  midget  tricking  \n",
       "0      0.0          0.0     0.0       0.0  \n",
       "1      0.0          0.0     0.0       0.0  \n",
       "2      0.0          0.0     0.0       0.0  \n",
       "3      0.0          0.0     0.0       0.0  \n",
       "4      0.0          0.0     0.0       0.0  \n",
       "\n",
       "[5 rows x 6530 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터프레임 변환\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(X_train_vectorized.toarray(), columns=vect.vocabulary_.keys())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#로지스틱 회귀모형\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(random_state=10)\n",
    "logit.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍정 리뷰 모델 평가 함수\n",
    "def pos_review(model):\n",
    "    count_all = 0\n",
    "    count = 0\n",
    "    num = 100\n",
    "    tests1 = []\n",
    "    for idx in range(0, num):\n",
    "        pos_review_test = (glob.glob('c:/data/imdb/test/pos/*.txt'))[idx]\n",
    "        f = open(pos_review_test, 'r', encoding='utf-8')\n",
    "        tests1.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests1:\n",
    "        pred = model.predict(vect.transform(test))\n",
    "        result = pred[0]\n",
    "        if result == 'pos':\n",
    "            count += 1\n",
    "        count_all += 1\n",
    "    rate = count * 100 / count_all\n",
    "    print(f'긍정 리뷰 분류정확도: {rate:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#부정 리뷰 모델 평가 함수\n",
    "def neg_review(model):\n",
    "    count_all = 0\n",
    "    count = 0\n",
    "    num = 100\n",
    "    tests2 = []\n",
    "    for idx in range(0, num):\n",
    "        neg_review_test = (glob.glob('c:/data/imdb/test/neg/*.txt'))[idx]\n",
    "        f = open(neg_review_test, 'r', encoding='utf-8')\n",
    "        tests2.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests2:\n",
    "        pred = model.predict(vect.transform(test))\n",
    "        result = pred[0]\n",
    "        if result == 'neg':\n",
    "            count += 1\n",
    "        count_all += 1\n",
    "    rate = count * 100 / count_all\n",
    "    print(f'부정 리뷰 분류정확도: {rate:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 리뷰 분류정확도: 66.0%\n",
      "부정 리뷰 분류정확도: 81.0%\n"
     ]
    }
   ],
   "source": [
    "pos_review(logit)\n",
    "neg_review(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 리뷰 분류정확도: 39.0%\n",
      "부정 리뷰 분류정확도: 66.0%\n"
     ]
    }
   ],
   "source": [
    "#의사결정나무 모형\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(X_train_vectorized, class_Index)\n",
    "pos_review(tree)\n",
    "neg_review(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 리뷰 분류정확도: 44.0%\n",
      "부정 리뷰 분류정확도: 75.0%\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트 모형\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state=10)\n",
    "forest.fit(X_train_vectorized, class_Index)\n",
    "pos_review(forest)\n",
    "neg_review(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 리뷰 분류정확도: 34.0%\n",
      "부정 리뷰 분류정확도: 85.0%\n"
     ]
    }
   ],
   "source": [
    "#KNN 모형\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train_vectorized, class_Index)\n",
    "pos_review(knn)\n",
    "neg_review(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 리뷰 분류정확도: 58.0%\n",
      "부정 리뷰 분류정확도: 79.0%\n"
     ]
    }
   ],
   "source": [
    "#인공신경망 모형\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=10)\n",
    "mlp.fit(X_train_vectorized, class_Index)\n",
    "pos_review(mlp)\n",
    "neg_review(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 리뷰 분류정확도: 63.0%\n",
      "부정 리뷰 분류정확도: 87.0%\n"
     ]
    }
   ],
   "source": [
    "#SVM 모형\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=10)\n",
    "svm.fit(X_train_vectorized, class_Index)\n",
    "pos_review(svm)\n",
    "neg_review(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('This is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('This is my best work.', 'pos'),\n",
    "    ('What an awesome view', 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('He is my sworn enemy!', 'neg'),\n",
    "    ('My boss is horrible.', 'neg')\n",
    "]\n",
    "\n",
    "test = [\n",
    "    ('The beer was good.', 'pos'),\n",
    "    ('I do not enjoy my job', 'neg'),\n",
    "    ('I am not feeling dandy today.', 'neg'),\n",
    "    ('I feel amazing!', 'pos'),\n",
    "    ('Gary is a friend of mine.', 'pos'),\n",
    "    (\"I can't believe I'm doing this.\", 'neg')\n",
    "]\n",
    "\n",
    "cl = NaiveBayesClassifier(train)\n",
    "print(cl.classify('Their burgers are amazing'))\n",
    "print(cl.classify(\"I don't like their pizza.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#여러 문장을 종합하여 분류\n",
    "blob = TextBlob('The beer was amazing. But the hangover was horrible. My boss was not happy.',\n",
    "                classifier=cl)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer was amazing. ==> pos\n",
      "But the hangover was horrible. ==> neg\n",
      "My boss was not happy. ==> neg\n",
      "The beer was good. ==> pos\n",
      "I do not enjoy my job ==> neg\n",
      "I am not feeling dandy today. ==> neg\n",
      "I feel amazing! ==> pos\n",
      "Gary is a friend of mine. ==> neg\n",
      "I can't believe I'm doing this. ==> neg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#개별 문장으로 분류\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence, '==>', sentence.classify())\n",
    "for row in test:\n",
    "    print(row[0], '==>', cl.classify(row[0]))\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(this) = True              neg : pos    =      2.3 : 1.0\n",
      "          contains(this) = False             pos : neg    =      1.8 : 1.0\n",
      "          contains(This) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "#한글 - textblob\n",
    "train = [\n",
    "    ('샌드위치 좋아해요', 'pos'),\n",
    "    ('너무 좋은 곳이예요', 'pos'),\n",
    "    ('너무 맛있어요', 'pos'),\n",
    "    ('내가 제일 좋아하는 곳이예요', 'pos'),\n",
    "    ('친한 친구예요', 'pos'),\n",
    "    ('이 사람은 믿을 수 없어요', 'neg'),\n",
    "    ('별로 안좋은 곳이네요', 'neg'),\n",
    "    (\"맛이 별로네요\", 'neg'),\n",
    "    ('경치가 별로예요', 'neg'),\n",
    "    ('별로 볼게 없네요', 'neg')\n",
    "]\n",
    "\n",
    "test = [\n",
    "    ('최고의 음료수', 'pos'),\n",
    "    ('별로 안좋아요', 'neg'),\n",
    "    ('이번주는 컨디션이 안좋아요', 'neg'),\n",
    "    ('너무 좋아요', 'pos'),\n",
    "    ('나와 가장 친해요', 'pos'),\n",
    "    (\"믿을 수 없어요\", 'neg')\n",
    "]\n",
    "\n",
    "cl = NaiveBayesClassifier(train)\n",
    "print(cl.classify('맛있는 음식이네요'))  \n",
    "print(cl.classify(\"피자맛이 별로네요\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#여러 문장을 종합하여 분류\n",
    "blob = TextBlob(\"맛있는 음식이네요. 피자는 별로네요. 서비스는 좋네요.\", classifier=cl)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맛있는 음식이네요. ==> pos\n",
      "피자는 별로네요. ==> neg\n",
      "서비스는 좋네요. ==> pos\n",
      "최고의 음료수 ==> pos\n",
      "별로 안좋아요 ==> neg\n",
      "이번주는 컨디션이 안좋아요 ==> pos\n",
      "너무 좋아요 ==> pos\n",
      "나와 가장 친해요 ==> pos\n",
      "믿을 수 없어요 ==> neg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#개별 문장으로 분류\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence, '==>', sentence.classify())\n",
    "for row in test:\n",
    "    print(row[0],'==>', cl.classify(row[0]))\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(곳이예요) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(너무) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(별로) = False             pos : neg    =      1.6 : 1.0\n",
      "           contains(경치가) = False             pos : neg    =      1.2 : 1.0\n",
      "          contains(곳이네요) = False             pos : neg    =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
