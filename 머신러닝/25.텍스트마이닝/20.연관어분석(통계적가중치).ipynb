{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통계적 가중치 기반 연관어 분석\n",
    "- 통계적으로 가중치를 구한 후 두 단어 간의 유사도를 단어간의 연관도로 적용하는 방법\n",
    "    1. 단어마다 가중치를 할당해야 함(출현빈도, tf-idf 등으로 계산)\n",
    "    2. 단어간의 유사도 계산(cosine similarity 등의 방법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#긍정리뷰 100개 로드\n",
    "import glob\n",
    "pos_review = (glob.glob('c:/data/imdb/train/pos/*.txt'))[0:100]\n",
    "lines_pos = []\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except:\n",
    "        continue\n",
    "len(lines_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4001)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.06538462 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.23078109 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF가중치 할당\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tokenizer = RegexpTokenizer('[\\w]+') # 알파벳, 숫자, -\n",
    "stop_words = stopwords.words('english')\n",
    "vec = TfidfVectorizer(stop_words=stop_words)\n",
    "vector_lines_pos = vec.fit_transform(lines_pos)\n",
    "A = vector_lines_pos.toarray()\n",
    "print(A.shape)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4001, 100)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.06538462 0.23078109]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#단어간의 유사도를 구하기 위해 행렬 전치\n",
    "A = A.T\n",
    "print(A.shape)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1469, 108), 0.37803585968894865),\n",
       " ((1470, 108), 0.2189685434746738),\n",
       " ((1476, 108), 0.06407477897013734),\n",
       " ((1477, 108), 0.185189577514238),\n",
       " ((1480, 108), 0.20111036876169444),\n",
       " ((1489, 108), 0.06995711757772019),\n",
       " ((1496, 108), 0.10714874067068783),\n",
       " ((1503, 108), 0.30487333830091773),\n",
       " ((1504, 108), 0.30487333830091773),\n",
       " ((1512, 108), 0.30487333830091773)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#코사인 유사도 계산\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# 희소행렬로 변환\n",
    "A_sparse = sparse.csr_matrix(A)\n",
    "similarities_sparse = cosine_similarity(A_sparse, dense_output=False)\n",
    "# todok(): 행렬을 딕셔너리 형태로 변환\n",
    "list(similarities_sparse.todok().items())[35000:35010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['06', '10', '100', ..., 'zhu', 'zone', 'zooms'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names_out([1469])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3971, 3372)</td>\n",
       "      <td>0.499961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3372, 3971)</td>\n",
       "      <td>0.499961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1192, 2554)</td>\n",
       "      <td>0.499958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2554, 1192)</td>\n",
       "      <td>0.499958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2468, 1321)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2468, 710)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(710, 2468)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1321, 2468)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2146, 889)</td>\n",
       "      <td>0.499909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(889, 2146)</td>\n",
       "      <td>0.499909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words    weight\n",
       "0  (3971, 3372)  0.499961\n",
       "1  (3372, 3971)  0.499961\n",
       "2  (1192, 2554)  0.499958\n",
       "3  (2554, 1192)  0.499958\n",
       "4  (2468, 1321)  0.499957\n",
       "5   (2468, 710)  0.499957\n",
       "6   (710, 2468)  0.499957\n",
       "7  (1321, 2468)  0.499957\n",
       "8   (2146, 889)  0.499909\n",
       "9   (889, 2146)  0.499909"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결과값을 데이터프레임으로 출력\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(list(similarities_sparse.todok().items()), columns=['words', 'weight'])\n",
    "df2 = df.sort_values('weight', ascending=False)\n",
    "df2 = df2.reset_index(drop=True)\n",
    "# 자신끼리 연결된 항목을 제외\n",
    "df3 = df2[np.round(df2['weight']) < 1]\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writers, stop => 0.50\n",
      "stop, writers => 0.50\n",
      "essence, past => 0.50\n",
      "past, essence => 0.50\n",
      "older, farewell => 0.50\n",
      "older, concubine => 0.50\n",
      "concubine, older => 0.50\n",
      "farewell, older => 0.50\n",
      "made, deeply => 0.50\n",
      "deeply, made => 0.50\n",
      "classes, watch => 0.50\n",
      "watch, classes => 0.50\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(df3.iterrows()): # iterrows: 데이터프레임 개별 행 처리\n",
    "    a = vec.get_feature_names_out()[row[1][0][0]]\n",
    "    b = vec.get_feature_names_out()[row[1][0][1]]\n",
    "    print(f'{a}, {b} => {row[1][1]:.2f}')    \n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
